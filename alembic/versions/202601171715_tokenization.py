"""tokenization

Revision ID: a88528cc2d55
Revises: 0be1556891b8
Create Date: 2026-01-17 17:15:10.506295

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from pgvector.sqlalchemy import Vector as VECTOR


# revision identifiers, used by Alembic.
revision: str = 'a88528cc2d55'
down_revision: Union[str, Sequence[str], None] = '0be1556891b8'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Ensure pgvector extension is available in the database
    op.execute("CREATE EXTENSION IF NOT EXISTS vector")
    op.create_table('topic_embeddings',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('topic_id', sa.BigInteger(), nullable=False),
    sa.Column('embedding', VECTOR(1536), nullable=False),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=False),
    sa.ForeignKeyConstraint(['topic_id'], ['topics.id'], ),
    sa.PrimaryKeyConstraint('id')
    )
    
    # Add tokenized column as nullable first
    op.add_column('messages', sa.Column('tokenized', sa.Boolean(), nullable=True))
    # Update existing records with default value
    op.execute("UPDATE messages SET tokenized = false WHERE tokenized IS NULL")
    # Change column to NOT NULL
    op.alter_column('messages', 'tokenized', nullable=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_column('messages', 'tokenized')
    op.drop_table('topic_embeddings')
    # Optionally remove the extension when downgrading
    op.execute("DROP EXTENSION IF EXISTS vector")
    # ### end Alembic commands ###
